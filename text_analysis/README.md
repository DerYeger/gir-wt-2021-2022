# Exercise 2

Execute the `main` function of `code/exercise2.py` to run all three parts.
Reference the sections below before starting.

## Part 1 & Part 2

First, place the [provided model](https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip) in ./model.
It should have its default name of "wiki-news-300d-1M-subword.vec".

## Part 3

Dataset from https://www.kaggle.com/rtatman/3-million-german-sentences/version/1?select=deu_news_2015_3M-sentences.txt.

D. Goldhahn, T. Eckart & U. Quasthoff: Building Large Monolingual Dictionaries at the Leipzig Corpora Collection: From 100 to 200 Languages.
In: Proceedings of the 8th International Language Resources and Evaluation (LREC'12), 2012

Actual results can vary because of random weight initialization of the training algorithm.
