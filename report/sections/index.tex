\section{Inverted Index}
\label{sec:index}

\subsection{Data structure}

Our inverted index is a Python dictionary using tokens as keys and numpy arrays as values.
The numpy arrays are two dimensional, with each sub-array containing two elements, the id of an article and the number of occurrences of the given token in that article.
While we initially used plain Python lists with tuples, the memory usage was exceeding 16GB, which rendered the program unusable on the test machine.
Using numpy arrays with the \verb|dtype| \verb|numpy.uint32| reduced the memory usage of the index to less than 3.6GB.
As a tradeoff, inserting new entries is considerably slower than appending to Python lists.

\subsection{Parsing}

BeautifulSoup is used for parsing.
For each article, its title and, if available, categories and body are included.
The text content of these tags is then concatenated and subsequently tokenized.
Afterward, the occurrences of each token are counted and inserted into the inverted index alongside the article's id.

Additionally, metadata is stored for each article.
Associated with its unique id, title, filename and word count of each parsed article are stored in a dictionary.
While the filename enables targeted retrieval of an article, the word count is used for scoring functions.

\subsection{Saving and loading}

To make re-indexing after program restarts optional, saving and loading of the inverted index and article metadata was implemented.
The inverted index itself is being saved and loaded using numpy's \verb|save| and \verb|load| methods.
The resulting file \verb|inverted_index.npy| is about 2.02 GB big.
Article metadata and average word count of all articles are saved alongside it in the \verb|code/tables| directory.
